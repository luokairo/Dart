  0%|                                                                                                                                                               | 0/100 [00:00<?, ?it/s][[34m2025-01-13 23:18:24[0m] Begin epoch 0...
  0%|                                                                                                                                                             | 0/13617 [00:53<?, ?it/s]
  0%|                                                                                                                                                               | 0/100 [00:53<?, ?it/s]
Traceback (most recent call last):
  File "/fs/scratch/PAS2473/ICML2025/dart/training/vq_train.py", line 437, in <module>
    main(args)
  File "/fs/scratch/PAS2473/ICML2025/dart/training/vq_train.py", line 276, in main
    out = vae_model(imgs)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 465, in _fn
    return fn(*args, **kwargs)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/fs/scratch/PAS2473/ICML2025/dart/models/autoencoder/dart_autoencoder.py", line 138, in forward
    def forward(
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 632, in _fn
    return fn(*args, **kwargs)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1100, in forward
    return compiled_fn(full_args)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 321, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 124, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 667, in inner_fn
    outs = compiled_fn(args)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 488, in wrapper
    return compiled_fn(runtime_args)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1478, in __call__
    return self.current_callable(inputs)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/utils.py", line 1977, in run
    return model(new_inputs)
  File "/tmp/slurmtmp.281815/torchinductor_brucewan666/4v/c4vbfexts73perixpbz6ho4ieln5fdfr2x5omedw53cniyzdrf2m.py", line 3326, in call
    triton_poi_fused_native_group_norm_silu_6.run(buf21, buf2, arg1_1, buf16, arg10_1, buf17, buf18, arg11_1, arg12_1, 5368709120, grid=grid(5368709120), stream=stream0)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 836, in run
    self.autotune_to_one_config(*args, grid=grid, **kwargs)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 729, in autotune_to_one_config
    timings = self.benchmark_all_configs(*args, **kwargs)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 704, in benchmark_all_configs
    timings = {
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 705, in <dictcomp>
    launcher: self.bench(launcher, *args, **kwargs)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 675, in bench
    return benchmarker.benchmark_gpu(kernel_call, rep=40, fast_flush=True)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/runtime/benchmarking.py", line 66, in wrapper
    return fn(self, *args, **kwargs)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/runtime/benchmarking.py", line 201, in benchmark_gpu
    return self.triton_do_bench(_callable, **kwargs, return_mode="median")
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/triton/testing.py", line 106, in do_bench
    fn()
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 662, in kernel_call
    cloned_args, cloned_kwargs = self.clone_args(*args, **kwargs)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 688, in clone_args
    cloned_args.append(clone_preserve_strides(arg))
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/utils.py", line 1986, in clone_preserve_strides
    buffer = torch.as_strided(x, (needed_size,), (1,)).clone()
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 0 has a total capacity of 79.14 GiB of which 16.38 GiB is free. Including non-PyTorch memory, this process has 62.73 GiB memory in use. Of the allocated memory 61.10 GiB is allocated by PyTorch, and 43.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]: Traceback (most recent call last):
[rank0]:   File "/fs/scratch/PAS2473/ICML2025/dart/training/vq_train.py", line 437, in <module>
[rank0]:     main(args)
[rank0]:   File "/fs/scratch/PAS2473/ICML2025/dart/training/vq_train.py", line 276, in main
[rank0]:     out = vae_model(imgs)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 465, in _fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/fs/scratch/PAS2473/ICML2025/dart/models/autoencoder/dart_autoencoder.py", line 138, in forward
[rank0]:     def forward(
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 632, in _fn
[rank0]:     return fn(*args, **kwargs)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1100, in forward
[rank0]:     return compiled_fn(full_args)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 321, in runtime_wrapper
[rank0]:     all_outs = call_func_at_runtime_with_args(
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/utils.py", line 124, in call_func_at_runtime_with_args
[rank0]:     out = normalize_as_list(f(args))
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 667, in inner_fn
[rank0]:     outs = compiled_fn(args)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 488, in wrapper
[rank0]:     return compiled_fn(runtime_args)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/codecache.py", line 1478, in __call__
[rank0]:     return self.current_callable(inputs)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/utils.py", line 1977, in run
[rank0]:     return model(new_inputs)
[rank0]:   File "/tmp/slurmtmp.281815/torchinductor_brucewan666/4v/c4vbfexts73perixpbz6ho4ieln5fdfr2x5omedw53cniyzdrf2m.py", line 3326, in call
[rank0]:     triton_poi_fused_native_group_norm_silu_6.run(buf21, buf2, arg1_1, buf16, arg10_1, buf17, buf18, arg11_1, arg12_1, 5368709120, grid=grid(5368709120), stream=stream0)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 836, in run
[rank0]:     self.autotune_to_one_config(*args, grid=grid, **kwargs)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 729, in autotune_to_one_config
[rank0]:     timings = self.benchmark_all_configs(*args, **kwargs)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 704, in benchmark_all_configs
[rank0]:     timings = {
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 705, in <dictcomp>
[rank0]:     launcher: self.bench(launcher, *args, **kwargs)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 675, in bench
[rank0]:     return benchmarker.benchmark_gpu(kernel_call, rep=40, fast_flush=True)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/runtime/benchmarking.py", line 66, in wrapper
[rank0]:     return fn(self, *args, **kwargs)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/runtime/benchmarking.py", line 201, in benchmark_gpu
[rank0]:     return self.triton_do_bench(_callable, **kwargs, return_mode="median")
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/triton/testing.py", line 106, in do_bench
[rank0]:     fn()
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 662, in kernel_call
[rank0]:     cloned_args, cloned_kwargs = self.clone_args(*args, **kwargs)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 688, in clone_args
[rank0]:     cloned_args.append(clone_preserve_strides(arg))
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_inductor/utils.py", line 1986, in clone_preserve_strides
[rank0]:     buffer = torch.as_strided(x, (needed_size,), (1,)).clone()
[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 0 has a total capacity of 79.14 GiB of which 16.38 GiB is free. Including non-PyTorch memory, this process has 62.73 GiB memory in use. Of the allocated memory 61.10 GiB is allocated by PyTorch, and 43.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
