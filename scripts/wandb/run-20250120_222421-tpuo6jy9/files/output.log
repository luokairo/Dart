  0%|                                                                                                         | 0/4 [00:00<?, ?it/s][[34m2025-01-20 22:24:22[0m] Begin epoch 0...
                                                                                                                                    We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
/fs/scratch/PAS2473/ICML2025/dart/models/autoencoder/quantize/dart_quantize.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
  0%|                                                                                                      | 0/2802 [00:07<?, ?it/s]
  0%|                                                                                                         | 0/4 [00:07<?, ?it/s]
Traceback (most recent call last):
  File "/fs/scratch/PAS2473/ICML2025/dart/training/vq_train.py", line 548, in <module>
    main(args)
  File "/fs/scratch/PAS2473/ICML2025/dart/training/vq_train.py", line 318, in main
    out = vae_model(imgs, context_tenser)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/fs/scratch/PAS2473/ICML2025/dart/models/autoencoder/dart_autoencoder.py", line 174, in forward
    h_BChw, routing_outcome = self.router(
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/fs/scratch/PAS2473/ICML2025/dart/models/router/mlp_router.py", line 70, in forward
    con_weighted_embeds = con_weight * con_h_BChw
RuntimeError: The size of tensor a (45) must match the size of tensor b (16) at non-singleton dimension 3
[rank0]: Traceback (most recent call last):
[rank0]:   File "/fs/scratch/PAS2473/ICML2025/dart/training/vq_train.py", line 548, in <module>
[rank0]:     main(args)
[rank0]:   File "/fs/scratch/PAS2473/ICML2025/dart/training/vq_train.py", line 318, in main
[rank0]:     out = vae_model(imgs, context_tenser)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1643, in forward
[rank0]:     else self._run_ddp_forward(*inputs, **kwargs)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1459, in _run_ddp_forward
[rank0]:     return self.module(*inputs, **kwargs)  # type: ignore[index]
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/fs/scratch/PAS2473/ICML2025/dart/models/autoencoder/dart_autoencoder.py", line 174, in forward
[rank0]:     h_BChw, routing_outcome = self.router(
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/fs/scratch/PAS2473/ICML2025/dart/models/router/mlp_router.py", line 70, in forward
[rank0]:     con_weighted_embeds = con_weight * con_h_BChw
[rank0]: RuntimeError: The size of tensor a (45) must match the size of tensor b (16) at non-singleton dimension 3
