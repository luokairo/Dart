  0%|                                                                                                         | 0/4 [00:00<?, ?it/s][[34m2025-01-20 22:53:18[0m] Begin epoch 0...
                                                                                                                                    We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
/fs/scratch/PAS2473/ICML2025/dart/models/autoencoder/quantize/dart_quantize.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):
                                                                                                                                    [[34m2025-01-20 22:56:04[0m] (Generator) rec_loss: 0.0124, perceptual_loss: 0.1076, vq_loss: 6.6424,codebook_usage: 99.8047, generator_adv_loss: 0.0000, disc_adaptive_weight: 1.0000, disc_weight: 0.0000
[[34m2025-01-20 22:56:05[0m] (Discriminator) discriminator_adv_loss: 0.0000, disc_weight: 0.0000, logits_real: -1.4961, logits_fake: -1.4980
[[34m2025-01-20 22:56:05[0m] (step=0000050) Train Loss: 7.0404, Batch rFID: 371.6694, Batch gFID: 3532.6455, Avg rFID: 467.1262, Avg gFID: 3346.9463, continuous: 0.5162, discrete: 0.4838Train Steps/Sec: 0.30
                                                                                                                                    /fs/scratch/PAS2473/ICML2025/dart/models/autoencoder/quantize/dart_quantize.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=False):                                                  | 50/2802 [02:46<2:29:31,  3.26s/it]
                                                                                                                                    [[34m2025-01-20 22:58:41[0m] (Generator) rec_loss: 0.0114, perceptual_loss: 0.1127, vq_loss: 6.8273,codebook_usage: 99.8779, generator_adv_loss: 0.0000, disc_adaptive_weight: 1.0000, disc_weight: 0.0000
[[34m2025-01-20 22:58:42[0m] (Discriminator) discriminator_adv_loss: 0.0000, disc_weight: 0.0000, logits_real: -1.5288, logits_fake: -1.5236
[[34m2025-01-20 22:58:42[0m] (step=0000100) Train Loss: 7.1344, Batch rFID: 431.4656, Batch gFID: 3464.4946, Avg rFID: 432.8537, Avg gFID: 3454.2371, continuous: 0.5315, discrete: 0.4685Train Steps/Sec: 0.32
                                                                                                                                    [[34m2025-01-20 23:01:17[0m] (Generator) rec_loss: 0.0090, perceptual_loss: 0.0986, vq_loss: 6.5644,codebook_usage: 100.0000, generator_adv_loss: 0.0000, disc_adaptive_weight: 1.0000, disc_weight: 0.0000
[[34m2025-01-20 23:01:18[0m] (Discriminator) discriminator_adv_loss: 0.0000, disc_weight: 0.0000, logits_real: -1.5139, logits_fake: -1.5124
[[34m2025-01-20 23:01:18[0m] (step=0000150) Train Loss: 7.1442, Batch rFID: 408.4529, Batch gFID: 3335.8232, Avg rFID: 426.9309, Avg gFID: 3486.4599, continuous: 0.5388, discrete: 0.4612Train Steps/Sec: 0.32
                                                                                                                                    [[34m2025-01-20 23:03:54[0m] (Generator) rec_loss: 0.0105, perceptual_loss: 0.1066, vq_loss: 7.4742,codebook_usage: 99.7559, generator_adv_loss: 0.0000, disc_adaptive_weight: 1.0000, disc_weight: 0.0000
[[34m2025-01-20 23:03:54[0m] (Discriminator) discriminator_adv_loss: 0.0000, disc_weight: 0.0000, logits_real: -1.5103, logits_fake: -1.5085
[[34m2025-01-20 23:03:54[0m] (step=0000200) Train Loss: 7.0970, Batch rFID: 457.8018, Batch gFID: 3586.3569, Avg rFID: 430.1555, Avg gFID: 3508.8402, continuous: 0.5611, discrete: 0.4389Train Steps/Sec: 0.32
                                                                                                                                    [[34m2025-01-20 23:06:30[0m] (Generator) rec_loss: 0.0148, perceptual_loss: 0.1157, vq_loss: 8.1133,codebook_usage: 99.7559, generator_adv_loss: 0.0000, disc_adaptive_weight: 1.0000, disc_weight: 0.0000
[[34m2025-01-20 23:06:31[0m] (Discriminator) discriminator_adv_loss: 0.0000, disc_weight: 0.0000, logits_real: -1.5372, logits_fake: -1.5351
[[34m2025-01-20 23:06:31[0m] (step=0000250) Train Loss: 7.1127, Batch rFID: 509.4463, Batch gFID: 3443.6733, Avg rFID: 422.5819, Avg gFID: 3523.7858, continuous: 0.5748, discrete: 0.4252Train Steps/Sec: 0.32
                                                                                                                                    [[34m2025-01-20 23:09:06[0m] (Generator) rec_loss: 0.0111, perceptual_loss: 0.1039, vq_loss: 7.0697,codebook_usage: 99.6582, generator_adv_loss: 0.0000, disc_adaptive_weight: 1.0000, disc_weight: 0.0000
[[34m2025-01-20 23:09:07[0m] (Discriminator) discriminator_adv_loss: 0.0000, disc_weight: 0.0000, logits_real: -1.5226, logits_fake: -1.5195
[[34m2025-01-20 23:09:07[0m] (step=0000300) Train Loss: 7.0898, Batch rFID: 449.0876, Batch gFID: 3283.7939, Avg rFID: 417.8704, Avg gFID: 3517.6449, continuous: 0.5784, discrete: 0.4216Train Steps/Sec: 0.32
                                                                                                                                    [[34m2025-01-20 23:11:43[0m] (Generator) rec_loss: 0.0110, perceptual_loss: 0.0975, vq_loss: 7.2701,codebook_usage: 99.8535, generator_adv_loss: 0.0000, disc_adaptive_weight: 1.0000, disc_weight: 0.0000
[[34m2025-01-20 23:11:44[0m] (Discriminator) discriminator_adv_loss: 0.0000, disc_weight: 0.0000, logits_real: -1.5114, logits_fake: -1.5089
[[34m2025-01-20 23:11:44[0m] (step=0000350) Train Loss: 7.0830, Batch rFID: 376.6299, Batch gFID: 3336.7454, Avg rFID: 415.4971, Avg gFID: 3494.8506, continuous: 0.5970, discrete: 0.4030Train Steps/Sec: 0.32
                                                                                                                                    [[34m2025-01-20 23:14:19[0m] (Generator) rec_loss: 0.0111, perceptual_loss: 0.1038, vq_loss: 7.2037,codebook_usage: 99.7559, generator_adv_loss: 0.0000, disc_adaptive_weight: 1.0000, disc_weight: 0.0000
[[34m2025-01-20 23:14:20[0m] (Discriminator) discriminator_adv_loss: 0.0000, disc_weight: 0.0000, logits_real: -1.5281, logits_fake: -1.5266
[[34m2025-01-20 23:14:20[0m] (step=0000400) Train Loss: 7.0595, Batch rFID: 339.3318, Batch gFID: 3655.2510, Avg rFID: 426.4652, Avg gFID: 3537.0729, continuous: 0.6181, discrete: 0.3819Train Steps/Sec: 0.32
                                                                                                                                    [[34m2025-01-20 23:16:55[0m] (Generator) rec_loss: 0.0090, perceptual_loss: 0.0977, vq_loss: 6.3491,codebook_usage: 99.8535, generator_adv_loss: 0.0000, disc_adaptive_weight: 1.0000, disc_weight: 0.0000
[[34m2025-01-20 23:16:56[0m] (Discriminator) discriminator_adv_loss: 0.0000, disc_weight: 0.0000, logits_real: -1.5096, logits_fake: -1.5059
[[34m2025-01-20 23:16:56[0m] (step=0000450) Train Loss: 7.0998, Batch rFID: 366.8394, Batch gFID: 3373.6936, Avg rFID: 400.5918, Avg gFID: 3470.8087, continuous: 0.6347, discrete: 0.3653Train Steps/Sec: 0.32
                                                                                                                                    [[34m2025-01-20 23:19:31[0m] (Generator) rec_loss: 0.0100, perceptual_loss: 0.0945, vq_loss: 7.0540,codebook_usage: 99.8291, generator_adv_loss: 0.0000, disc_adaptive_weight: 1.0000, disc_weight: 0.0000
[[34m2025-01-20 23:19:32[0m] (Discriminator) discriminator_adv_loss: 0.0000, disc_weight: 0.0000, logits_real: -1.5067, logits_fake: -1.5075
[[34m2025-01-20 23:19:32[0m] (step=0000500) Train Loss: 7.1620, Batch rFID: 382.9128, Batch gFID: 3434.5200, Avg rFID: 411.2640, Avg gFID: 3509.1096, continuous: 0.6458, discrete: 0.3542Train Steps/Sec: 0.32
                                                                                                                                    [[34m2025-01-20 23:22:08[0m] (Generator) rec_loss: 0.0126, perceptual_loss: 0.1051, vq_loss: 7.8601,codebook_usage: 99.8291, generator_adv_loss: 0.0000, disc_adaptive_weight: 1.0000, disc_weight: 0.0000
[[34m2025-01-20 23:22:08[0m] (Discriminator) discriminator_adv_loss: 0.0000, disc_weight: 0.0000, logits_real: -1.5271, logits_fake: -1.5240
[[34m2025-01-20 23:22:08[0m] (step=0000550) Train Loss: 7.0521, Batch rFID: 464.3115, Batch gFID: 3448.5615, Avg rFID: 399.4837, Avg gFID: 3465.6458, continuous: 0.6517, discrete: 0.3483Train Steps/Sec: 0.32
                                                                                                                                    [[34m2025-01-20 23:24:44[0m] (Generator) rec_loss: 0.0101, perceptual_loss: 0.0953, vq_loss: 7.6204,codebook_usage: 99.7314, generator_adv_loss: 0.0000, disc_adaptive_weight: 1.0000, disc_weight: 0.0000
[[34m2025-01-20 23:24:45[0m] (Discriminator) discriminator_adv_loss: 0.0000, disc_weight: 0.0000, logits_real: -1.5239, logits_fake: -1.5235
[[34m2025-01-20 23:24:45[0m] (step=0000600) Train Loss: 7.0862, Batch rFID: 439.3992, Batch gFID: 3410.7031, Avg rFID: 402.6239, Avg gFID: 3484.4467, continuous: 0.6537, discrete: 0.3463Train Steps/Sec: 0.32
                                                                                                                                    [[34m2025-01-20 23:27:20[0m] (Generator) rec_loss: 0.0104, perceptual_loss: 0.0993, vq_loss: 7.4110,codebook_usage: 99.8291, generator_adv_loss: 0.0000, disc_adaptive_weight: 1.0000, disc_weight: 0.0000
[[34m2025-01-20 23:27:21[0m] (Discriminator) discriminator_adv_loss: 0.0000, disc_weight: 0.0000, logits_real: -1.5085, logits_fake: -1.5075
[[34m2025-01-20 23:27:21[0m] (step=0000650) Train Loss: 7.0695, Batch rFID: 387.0859, Batch gFID: 3562.0798, Avg rFID: 406.2929, Avg gFID: 3497.1234, continuous: 0.6624, discrete: 0.3376Train Steps/Sec: 0.32
                                                                                                                                    [[34m2025-01-20 23:29:56[0m] (Generator) rec_loss: 0.0104, perceptual_loss: 0.1070, vq_loss: 7.3412,codebook_usage: 99.8047, generator_adv_loss: 0.0000, disc_adaptive_weight: 1.0000, disc_weight: 0.0000
[[34m2025-01-20 23:29:57[0m] (Discriminator) discriminator_adv_loss: 0.0000, disc_weight: 0.0000, logits_real: -1.5119, logits_fake: -1.5116
[[34m2025-01-20 23:29:57[0m] (step=0000700) Train Loss: 7.0756, Batch rFID: 412.1616, Batch gFID: 3309.5190, Avg rFID: 403.8552, Avg gFID: 3483.1083, continuous: 0.6837, discrete: 0.3163Train Steps/Sec: 0.32
 26%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                  | 735/2802 [38:31<1:48:20,  3.14s/it]
  0%|                                                                                                         | 0/4 [38:31<?, ?it/s]
Traceback (most recent call last):
  File "/fs/scratch/PAS2473/ICML2025/dart/training/vq_train.py", line 548, in <module>
    main(args)
  File "/fs/scratch/PAS2473/ICML2025/dart/training/vq_train.py", line 366, in main
    scaler.scale(loss_gen).backward()
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/fs/scratch/PAS2473/ICML2025/dart/training/vq_train.py", line 548, in <module>
[rank0]:     main(args)
[rank0]:   File "/fs/scratch/PAS2473/ICML2025/dart/training/vq_train.py", line 366, in main
[rank0]:     scaler.scale(loss_gen).backward()
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/_tensor.py", line 581, in backward
[rank0]:     torch.autograd.backward(
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/autograd/__init__.py", line 347, in backward
[rank0]:     _engine_run_backward(
[rank0]:   File "/users/PAS2473/brucewan666/anaconda3/envs/dart/lib/python3.10/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
[rank0]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank0]: KeyboardInterrupt
